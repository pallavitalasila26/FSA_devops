# Descriptive Statistics Table
descriptive_statistics:
  - category: "Central Tendency"
    statistics:
      - name: "Mean (μ or x̄)"
        description: "Average of all values; sum divided by count"
        formula: "μ = Σx / n"
        when_to_use: "Symmetric distributions without outliers"
        python: "<code>np.mean(data)</code> or <code>data.mean()</code>"
      - name: "Median"
        description: "Middle value when data is ordered; 50th percentile"
        formula: "Middle value or average of two middle values"
        when_to_use: "Skewed distributions or data with outliers"
        python: "<code>np.median(data)</code> or <code>data.median()</code>"
      - name: "Mode"
        description: "Most frequently occurring value(s)"
        formula: "Value with highest frequency"
        when_to_use: "Categorical data or multimodal distributions"
        python: "<code>statistics.mode(data)</code> or <code>data.mode()</code>"
      - name: "Trimmed Mean"
        description: "Mean after removing extreme values (e.g., top/bottom 5%)"
        formula: "Mean of remaining values after trimming"
        when_to_use: "Data with outliers but want mean-like measure"
        python: "<code>scipy.stats.trim_mean(data, 0.05)</code>"
  
  - category: "Spread"
    statistics:
      - name: "Range"
        description: "Difference between maximum and minimum values"
        formula: "Range = max - min"
        when_to_use: "Quick measure of spread; sensitive to outliers"
        python: "<code>np.ptp(data)</code> or <code>max(data) - min(data)</code>"
      - name: "Variance (σ² or s²)"
        description: "Average squared deviation from the mean"
        formula: "σ² = Σ(x - μ)² / n"
        when_to_use: "Understanding variability; basis for other stats"
        python: "<code>np.var(data)</code> or <code>data.var()</code>"
      - name: "Standard Deviation (σ or s)"
        description: "Square root of variance; typical distance from mean"
        formula: "σ = √(Σ(x - μ)² / n)"
        when_to_use: "Most common spread measure; same units as data"
        python: "<code>np.std(data)</code> or <code>data.std()</code>"
      - name: "Interquartile Range (IQR)"
        description: "Difference between 75th and 25th percentiles"
        formula: "IQR = Q3 - Q1"
        when_to_use: "Robust to outliers; used in boxplots"
        python: "<code>scipy.stats.iqr(data)</code> or <code>data.quantile(0.75) - data.quantile(0.25)</code>"
      - name: "Mean Absolute Deviation (MAD)"
        description: "Average absolute deviation from the mean"
        formula: "MAD = Σ|x - μ| / n"
        when_to_use: "Less sensitive to outliers than variance"
        python: "<code>np.mean(np.abs(data - np.mean(data)))</code>"
      - name: "Coefficient of Variation (CV)"
        description: "Relative standard deviation (standardized measure)"
        formula: "CV = (σ / μ) × 100%"
        when_to_use: "Comparing variability across different scales"
        python: "<code>(np.std(data) / np.mean(data)) * 100</code>"
  
  - category: "Shape"
    statistics:
      - name: "Skewness"
        description: "Measure of asymmetry in the distribution"
        formula: "Positive: right tail; Negative: left tail; 0: symmetric"
        when_to_use: "Assessing distribution symmetry"
        python: "<code>scipy.stats.skew(data)</code> or <code>data.skew()</code>"
      - name: "Kurtosis"
        description: "Measure of tailedness (outlier propensity)"
        formula: "Positive: heavy tails; Negative: light tails; 0: normal"
        when_to_use: "Identifying presence of outliers"
        python: "<code>scipy.stats.kurtosis(data)</code> or <code>data.kurtosis()</code>"

# Probability Distributions Table
probability_distributions:
  - type: "Discrete"
    distributions:
      - name: "Bernoulli"
        parameters: "p (probability of success)"
        description: "Single trial with two outcomes (success/failure)"
        python: "<code>stats.bernoulli.pmf(k, p)</code>"
        image: "bernoulli.png"
      - name: "Binomial"
        parameters: "n (trials), p (probability)"
        description: "Number of successes in n independent Bernoulli trials"
        python: "<code>stats.binom.pmf(k, n, p)</code>"
        image: "binomial.png"
      - name: "Poisson"
        parameters: "λ (lambda, rate)"
        description: "Number of events in fixed time/space interval"
        python: "<code>stats.poisson.pmf(k, mu)</code>"
        image: "poisson.png"
      - name: "Geometric"
        parameters: "p (probability of success)"
        description: "Number of trials until first success"
        python: "<code>stats.geom.pmf(k, p)</code>"
        image: "geometric.png"
  
  - type: "Continuous"
    distributions:
      - name: "Uniform"
        parameters: "a (min), b (max)"
        description: "All values in interval [a, b] equally likely"
        python: "<code>stats.uniform.pdf(x, a, b-a)</code>"
        image: "uniform.png"
      - name: "Normal (Gaussian)"
        parameters: "μ (mean), σ (std dev)"
        description: "Symmetric bell curve; most common distribution"
        python: "<code>stats.norm.pdf(x, mu, sigma)</code>"
        image: "normal.png"
      - name: "Exponential"
        parameters: "λ (rate)"
        description: "Time between events in Poisson process"
        python: "<code>stats.expon.pdf(x, scale=1/lambda)</code>"
        image: "exponential.png"
      - name: "Gamma"
        parameters: "k (shape), θ (scale)"
        description: "Generalizes exponential; sum of k exponential variables"
        python: "<code>stats.gamma.pdf(x, k, scale=theta)</code>"
        image: "gamma.png"
      - name: "Beta"
        parameters: "α (alpha), β (beta)"
        description: "Distribution on interval [0, 1]"
        python: "<code>stats.beta.pdf(x, alpha, beta)</code>"
        image: "beta.png"
      - name: "Chi-Square (χ²)"
        parameters: "df (degrees of freedom)"
        description: "Sum of squared standard normal variables"
        python: "<code>stats.chi2.pdf(x, df)</code>"
        image: "chi_square.png"
      - name: "Student's t"
        parameters: "df (degrees of freedom)"
        description: "Similar to normal but with heavier tails"
        python: "<code>stats.t.pdf(x, df)</code>"
        image: "t_distribution.png"
      - name: "F-Distribution"
        parameters: "df1, df2 (degrees of freedom)"
        description: "Ratio of two chi-square distributions"
        python: "<code>stats.f.pdf(x, df1, df2)</code>"
        image: "f_distribution.png"
      - name: "Pareto"
        parameters: "α (shape), xₘ (scale/minimum)"
        description: "Power law distribution; models 80/20 rule phenomena"
        python: "<code>stats.pareto.pdf(x, alpha, scale=xm)</code>"
        image: "pareto.png"

# Hypothesis Testing Table
hypothesis_tests:
  - situation: "Comparing distributions of categorical variables"
    independent_var: "None"
    dependent_var: "Categorical"
    parametric_test: "Chi-square test"
    nonparametric_test: "Fisher's exact test (for small samples)"
    p_value_interpretation: "Low p-value: Observed distribution differs from expected"

  - situation: "Comparing one sample to a known value"
    independent_var: "None"
    dependent_var: "Continuous"
    parametric_test: "One-sample T-test / Z-test"
    nonparametric_test: "Wilcoxon signed-rank test"
    p_value_interpretation: "Low p-value: Sample mean significantly differs from known value"

  - situation: "Testing normality of data"
    independent_var: "None"
    dependent_var: "Continuous"
    parametric_test: "Shapiro-Wilk test"
    nonparametric_test: "Kolmogorov-Smirnov test"
    p_value_interpretation: "Low p-value: Data significantly deviates from normal distribution"
  
  - situation: "Comparing sample distribution to theoretical distribution"
    independent_var: "None"
    dependent_var: "Continuous"
    parametric_test: "N/A"
    nonparametric_test: "Kolmogorov-Smirnov test"
    p_value_interpretation: "Low p-value: Sample distribution differs from theoretical distribution"

  - situation: "Testing independence of two categorical variables"
    independent_var: "Categorical"
    dependent_var: "Categorical"
    parametric_test: "Chi-square test of independence"
    nonparametric_test: "Fisher's exact test"
    p_value_interpretation: "Low p-value: Variables are dependent (not independent)"
  
  - situation: "Comparing two independent groups"
    independent_var: "Categorical"
    dependent_var: "Continuous"
    parametric_test: "Independent samples T-test / Two-sample Z-test"
    nonparametric_test: "Mann-Whitney U test (Wilcoxon rank-sum test)"
    p_value_interpretation: "Low p-value: Significant difference between the two groups"
  
  - situation: "Comparing two paired/dependent groups"
    independent_var: "Categorical"
    dependent_var: "Continuous"
    parametric_test: "Paired T-test"
    nonparametric_test: "Wilcoxon signed-rank test"
    p_value_interpretation: "Low p-value: Significant change between paired observations"
  
  - situation: "Comparing three or more independent groups"
    independent_var: "Categorical"
    dependent_var: "Continuous"
    parametric_test: "One-way ANOVA"
    nonparametric_test: "Kruskal-Wallis H test"
    p_value_interpretation: "Low p-value: At least one group differs from the others"
  
  - situation: "Comparing three or more paired/dependent groups"
    independent_var: "Categorical"
    dependent_var: "Continuous"
    parametric_test: "Repeated measures ANOVA"
    nonparametric_test: "Friedman test"
    p_value_interpretation: "Low p-value: Significant differences across repeated measurements"

  - situation: "Testing effects of two or more factors"
    independent_var: "Categorical"
    dependent_var: "Continuous"
    parametric_test: "Two-way ANOVA / Factorial ANOVA"
    nonparametric_test: "Scheirer-Ray-Hare test"
    p_value_interpretation: "Low p-value: Significant main effects or interaction effects"

  - situation: "Comparing variances between two groups"
    independent_var: "Categorical"
    dependent_var: "Continuous"
    parametric_test: "F-test (Levene's test)"
    nonparametric_test: "Levene's test / Fligner-Killeen test"
    p_value_interpretation: "Low p-value: Variances significantly differ between groups"

  - situation: "Testing relationship between two continuous variables"
    independent_var: "Continuous"
    dependent_var: "Continuous"
    parametric_test: "Pearson correlation"
    nonparametric_test: "Spearman rank correlation / Kendall's tau"
    p_value_interpretation: "Low p-value: Significant correlation exists between variables"